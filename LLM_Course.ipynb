{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqCDHHmW92ow"
   },
   "source": [
    "# Using Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hR5lfZ9ekSCc"
   },
   "source": [
    "## pipelines examples\n",
    "It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(\"I've been waiting for this sucking day my whole life.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dSZ9sWvT9Oo"
   },
   "source": [
    " zero-shot-classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(\n",
    "    \"This is a course about the business\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\",\n",
    "max_length=30,\n",
    "    num_return_sequences=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74xy1yRQnBr-"
   },
   "source": [
    "use the model from ModelHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = pipeline(\n",
    "    task=\"image-classification\", model=\"google/vit-base-patch16-224\"\n",
    ")\n",
    "result = image_classifier(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transcriber = pipeline(\n",
    "    task=\"automatic-speech-recognition\", model=\"openai/whisper-base.en\"\n",
    ")\n",
    "transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n",
    "# Output: {'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxViJ6mpCW2H"
   },
   "source": [
    "## Behind the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX-zgaLnGqLK"
   },
   "source": [
    "在环境里安装三个库，分别是datasets，evaluate，transformer[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dk7eyq_OCiOd"
   },
   "source": [
    "### 1)preprocessing with a tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUXVoPYBh2La"
   },
   "source": [
    "#### for general cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBQ1ZqGAE4ND"
   },
   "source": [
    "DEFINITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYlhihorDdWp"
   },
   "source": [
    "convert the **text** inputs into **numbers** that the model can make sense of\n",
    "1. inputs→words,subword,symbols(\"tokens\")\n",
    "2. tokens→integer\n",
    "3. adding additiional inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCb8J7GPGzVB"
   },
   "source": [
    "KEY POINTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctkguz6CG18Y"
   },
   "source": [
    " The tokenizer and model should always be from the same checkpoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9JgC_KfEy3c"
   },
   "source": [
    "CODE SHOWING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsKVOu2AE710"
   },
   "source": [
    "从transformer库中导入AutoTokenizier类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lM-Xh7RkFHOC"
   },
   "source": [
    "（Hugging Face等平台提供的\"checkpoint\"通常是训练完成的最终状态（或关键节点），供他人直接下载使用。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hL0BQ4FJFuSU"
   },
   "source": [
    "from_pretrained( )方法，该方法会自动获取传入的模型配套的tokenizer相关数据,并且返回一个AutoTokenizer类的一个对象（实例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JNnE7k7LC0a"
   },
   "source": [
    "然后给tokenizer传入我们的初始文本\n",
    "这里tokenizer是一个AutoTokenizer的实例，这个类有call方法，所以 tokenizer（）实际上是在调用这个call方法。\n",
    "\n",
    "**padding=True, truncation=True**（explain later）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYXDq6p0OrSk"
   },
   "source": [
    "“input_ids”input_ids contains two rows of integers (one for each sentence) that are the unique identifiers of the tokens in each sentence.\n",
    "\n",
    "**“attention_mask”**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgHZv9SkMB7L"
   },
   "source": [
    "这个时候就完成了pipeline（）的第一步，prepocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhsdjOo4htbL"
   },
   "source": [
    "#### for some special cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrm1aak3iBWe"
   },
   "source": [
    "##### batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCF-4ze5puFa"
   },
   "source": [
    "对于单个句子，要转化为二维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "sequence=\"I've been waiting for a HuggingFace course my whole life.\"\n",
    "\n",
    "tokens=tokenizer.tokenize(sequence)\n",
    "ids=tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "input_ids=torch.tensor([ids])\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqEAN-nBj0a_"
   },
   "source": [
    "此处input_ids=torch.tensor([ids])\n",
    "\n",
    "**1.使用PyTorch将Python列表转换为tensor有几个重要好处：**\n",
    "\n",
    "* GPU加速：PyTorch tensors可以在GPU上运行，大幅加速计算，特别是对于深度学习模型。\n",
    "\n",
    "* 批量处理：tensor可以方便地表示批量数据，模型可以一次性处理多个输入序列。\n",
    "\n",
    "* 自动微分：PyTorch tensors支持自动微分，这对训练神经网络至关重要。\n",
    "\n",
    "* 与模型兼容：HuggingFace模型期望输入是tensor格式，直接使用Python列表需要额外转换。\n",
    "\n",
    "* 优化内存布局：tensor在内存中有更高效的存储方式，适合数值计算。\n",
    "\n",
    "2.**要多加一个[ ]转化为二维**\n",
    "\n",
    "3.注意打印出来的结果和下面的区别（上面没有CLS和SEP）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uChUX1J5lJNs"
   },
   "source": [
    "简化版本代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "sequence=\"I've been waiting for a HuggingFace course my whole life.\"\n",
    "\n",
    "tokenized_inputs = tokenizer(sequence, return_tensors=\"pt\")# pytorch tensor，返回的 tokenized_inputs 是一个字典，包含模型所需的所有输入字段\n",
    "print(tokenized_inputs[\"input_ids\"])#这里[\"input_ids\"]相当于就是在查字典，\n",
    "print(tokenized_inputs)#这样就是打印出字典的全部K：V，包括\"input_ids\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XB6oj6HiDp0"
   },
   "source": [
    "##### padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJZYbHu-qY6u"
   },
   "source": [
    "对于长度不同的多个句子，用padding补全，并且用attention mask设置为0消除padding对句子id的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "sequence=[\"I've been waiting for a HuggingFace course my whole life.\",\"life sucks,bro\"]\n",
    "tokenized_inputs=tokenizer(sequence,return_tensors=\"pt\",padding=True,truncation=True)# 注意这个True要大写\n",
    "print(tokenized_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1KYpHhTiI0H"
   },
   "source": [
    "##### truncating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hh45AhbvsG0m"
   },
   "source": [
    "用于处理太长的句子，具体用法见上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gz6qZVK0MP4H"
   },
   "source": [
    "### 2）passing the inputs through the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEKiML1UB0qR"
   },
   "source": [
    " “inputs\"→\"hidden states\"(features) :  a high-dimensional vector representing the contextual understanding of that input by the Transformer model.\n",
    "\n",
    "It generally has three dimensions:\n",
    "1.   Batch size: The number of sequences processed at a time (2 in our example).\n",
    "2. Sequence length: The length of the numerical representation of the sequence (16 in our example).\n",
    "3. Hidden size: The vector dimension of each model input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)\n",
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83QWwD-G7hGG"
   },
   "source": [
    "### 3）Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0FIFgvs75pS"
   },
   "source": [
    " \"logits\"→\"probabilities\" through a SoftMax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McKCPvVls-UX"
   },
   "source": [
    "# Fine-tuning a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUuNHnSPtb8D"
   },
   "source": [
    "## OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Same as before\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "sequences = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"This course is amazing!\",\n",
    "]\n",
    "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# This is new\n",
    "batch[\"labels\"] = torch.tensor([1, 1])\n",
    "\n",
    "optimizer = AdamW(model.parameters())\n",
    "loss = model(**batch).loss\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-J5Q9myNypr5"
   },
   "source": [
    "## check the trained data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Lwv7WkJthIX"
   },
   "source": [
    "Using MRPC dataset\n",
    "\n",
    "we get a DatasetDict object which contains the training set, the validation set, and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsfwL8nhxwVp"
   },
   "source": [
    "to access each pair of sentences in our raw_datasets object by indexing(like dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset=raw_datasets[\"train\"]\n",
    "raw_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset[3667]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26Uv8K9NyLdJ"
   },
   "source": [
    "to see the correspondence between \"labels\" and \"integers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpr-oYyNy5ZP"
   },
   "source": [
    "## Preprocessing a dataset（tokenize预处理）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k00pyX8K9wBN"
   },
   "source": [
    "tokenize the dataset(part of the preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "raw_datasets[\"train\"][\"sentence1\"][0]\n",
    "inputs = tokenizer(raw_datasets[\"train\"][\"sentence1\"][0],raw_datasets[\"train\"][\"sentence2\"][0], padding=True,truncation=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m55TvfuyCBFZ"
   },
   "source": [
    "但是Hugging Face Datasets 的特点，它的数据是用 Apache Arrow 格式存在磁盘上的。你可以按需读取一部分数据到内存（节省内存）。如果你直接一次性 tokenizer 全部数据，就失去了这种内存节省的优势"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjsDUH6P9wXd"
   },
   "source": [
    "Dataset.map() method( apply the tokenization function on all our datasets at once)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qHvfQCUDFMy"
   },
   "source": [
    "Dataset.map() 会对数据集的每一条数据调用你定义的函数，并返回一个新的 Dataset，不会一次性加载整个数据到内存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odwiWnm5DI71"
   },
   "source": [
    "好处：\n",
    "\n",
    "* 节省内存\n",
    "\n",
    "* 结果依然是 Dataset 类型，方便后续处理（比如 shuffle、split 等）\n",
    "\n",
    "* 可以同时做别的预处理（不只是分词）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(rawDatasets):\n",
    "  return tokenizer(rawDatasets[\"sentence1\"],rawDatasets[\"sentence2\"],truncation=True)\n",
    "#不要padding=True是因为效率不高\n",
    "# it’s better to pad the samples when we’re building a batch,\n",
    "# as then we only need to pad to the maximum length in that batch, and not the maximum length in the entire dataset.\n",
    "# This can save a lot of time and processing power when the inputs have very variable lengths!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset=raw_datasets.map(tokenize_function,batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsg6vbIwKhAx"
   },
   "source": [
    " applying your preprocessing function with map() by passing along a num_proc argument,this could speed up your preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxT3_WGzKMuU"
   },
   "source": [
    "### dynamic padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YElYZ-CmBWES"
   },
   "source": [
    "DataCollatorWithPadding 会自动把一个 batch 里不一样长的句子 pad 成一样长，方便模型处理，而且只 pad 到这个 batch 的最大长度，更节省资源。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qheUxRyUFPA6"
   },
   "source": [
    "完整代码见pycharm数据预处理全流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J96oIgtJUdQa"
   },
   "source": [
    "## Fine-tuning a model with the trainer API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wQHd-2McLQJ"
   },
   "source": [
    "对比本地GPU和colab云端GPU用时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = torch.nn.Linear(1000, 1000).to(device)\n",
    "data = torch.randn(10000, 1000).to(device)\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    model(data)\n",
    "print(f\"Time: {time.time() - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkgHwMrUnn4K"
   },
   "source": [
    "第一步：定义训练参数TraningArguments。配置核心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elQDNp-ZpgPh"
   },
   "source": [
    "第二步：加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "model=AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPNgwtJQqi6h"
   },
   "source": [
    "第三步：构建trainer类，这里是整个微调过程的核心封装，Trainer 帮我们把模型训练的各部分集成起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_bP89e5b8d7"
   },
   "source": [
    "第四步：加上评估evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
